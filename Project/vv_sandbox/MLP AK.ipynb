{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "from tqdm import tnrange\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gc\n",
    "import os\n",
    "%matplotlib inline  \n",
    "\n",
    "# alphabet\n",
    "import string\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(logit, target):\n",
    "    batch_size = len(target)\n",
    "    corrects = (torch.max(logit, 1)[1].view(target.size()).data == target.data).sum()\n",
    "    accuracy = 100.0 * corrects/batch_size\n",
    "    return accuracy.item()\n",
    "\n",
    "def nparam(ninputs,nhidden,noutputs):\n",
    "    return ninputs*(nhidden+1) + nhidden*(nhidden+1)+nhidden*(noutputs+1)\n",
    "\n",
    "# define the nnumber of parameters we need\n",
    "def nparam_MLP(N_INPUTS,N_HIDDEN,N_OUTPUTS):\n",
    "    input_to_hidden1 = (N_INPUTS+1)*N_HIDDEN #+1 for bias\n",
    "    hidden1_to_hidden2 = (N_HIDDEN + 1)*N_HIDDEN\n",
    "    hidden2_to_output = (N_OUTPUTS)*(N_HIDDEN+1)\n",
    "    return(sum([input_to_hidden1,hidden1_to_hidden2,hidden2_to_output]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a prototype MLP\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, n_inputs, n_hidden_neurons, n_output,  device):\n",
    "        super(MLP, self).__init__()\n",
    "        self.n_inputs = n_inputs # set the number of neurons in the input layer\n",
    "        self.n_hidden_neurons = n_hidden_neurons # how many neurons are in each hidden layer\n",
    "        self.n_output = n_output # set the number of neurons in the output layer\n",
    "        self.sig = nn.Sigmoid() # set the activation function \n",
    "        self.tanh = nn.Tanh()\n",
    "        self.n_hidden = n_hidden_neurons\n",
    "        self.encoder = nn.Linear(n_inputs, n_hidden_neurons) # encode input\n",
    "        self.recurrent = nn.Linear(n_hidden_neurons,n_hidden_neurons) # recurrent connections\n",
    "        self.decoder = nn.Linear(n_hidden_neurons, n_output) # decode output\n",
    "                \n",
    "    def forward(self, x):\n",
    "        self.hidden1 = self.tanh(self.encoder(x))\n",
    "        self.hidden2 = self.tanh(self.recurrent(self.hidden1))\n",
    "        self.output = self.decoder(self.hidden2)\n",
    "        return self.output\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test MLP on Anna Karenina\n",
    "# Load Anna Karenina\n",
    "from torch.utils.data import DataLoader # dataloader \n",
    "import sys\n",
    "sys.path.insert(0,'../final_project/Data/')\n",
    "from AnnaDataset_MLP import AnnaDataset, InvertAnna # import AK dataset\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# params\n",
    "BATCH_SIZE = 500 # how many batches we are running\n",
    "N_STEPS = 10 # How many characters are we inputting into the list at a time\n",
    "N_HIDDEN_NEURONS = 512 # how many neurons per hidden layer\n",
    "N_INPUTS = 77*N_STEPS\n",
    "N_OUTPUTS = 77\n",
    "N_LAYERS = 2 # 2 hidden layers\n",
    "N_EPOCHS = 11 # how many training epocs\n",
    "learning_rates = np.asarray([2]) # learning rates\n",
    "N_REPS = 1 # len(learning_rates) # the number of learning repetitions\n",
    "N_PARAMS = nparam_MLP(N_INPUTS,N_HIDDEN_NEURONS,N_OUTPUTS)\n",
    "gidx = int(N_HIDDEN_NEURONS/2)\n",
    "\n",
    "# regularization parameters\n",
    "lambdas = [0]#np.arange(0,1e-2,3e-3,dtype=np.float)\n",
    "N_LAMBDA = len(lambdas)\n",
    "\n",
    "# load data\n",
    "# list all transformations\n",
    "transform = transforms.Compose(\n",
    "    [transforms.Normalize((0,), (0.3,))])\n",
    "\n",
    "dataset = AnnaDataset(N_STEPS) # load the dataset\n",
    "trainloader = DataLoader(dataset, batch_size=BATCH_SIZE,\n",
    "                        shuffle=False, num_workers=4) # create a DataLoader. We want a batch of BATCH_SIZE entries\n",
    "testloader = DataLoader(dataset, batch_size=BATCH_SIZE,\n",
    "                        shuffle=False, num_workers=4) # create a DataLoader. We want a batch of BATCH_SIZE entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86bea614080343659e3ce8c82bf639e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91279953b0024edab4b922e31a5f33a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31.7720194026\n",
      "38.1439877457\n",
      "41.2838907327\n",
      "44.0883329078\n",
      "46.4393668624\n",
      "48.4286443707\n",
      "50.0045953536\n",
      "51.3178452898\n",
      "52.4393668624\n",
      "53.3819249426\n",
      "54.2236405412\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# regularizing digonal blocks of the partitioned RNN\n",
    "# initialize arrays of loss values and weights over the number of epohcs, the number of lambdas we are testing, and the number of reps. \n",
    "train_loss_P = np.zeros((N_EPOCHS,N_LAMBDA,N_REPS)) \n",
    "train_acc_P = np.zeros((N_EPOCHS,N_LAMBDA,N_REPS))\n",
    "test_loss_P = np.zeros((N_EPOCHS,N_LAMBDA,N_REPS))\n",
    "test_acc_P = np.zeros((N_EPOCHS,N_LAMBDA,N_REPS))\n",
    "Phist_P = np.zeros((N_PARAMS,N_EPOCHS,N_LAMBDA,N_REPS))\n",
    "\n",
    "model_P = [None]*N_LAMBDA*N_REPS # array of models\n",
    "regval_P = [] # array of regularization values\n",
    "for r in tnrange(N_REPS): # loop over the number of reps\n",
    "    for k in tnrange(N_LAMBDA): # loop over the number of different lambda values\n",
    "        reg_lambda = lambdas[k] # set the regularization lambda\n",
    "        model_path = './model_P_rep_{}_lambda_{:d}_10.pt'.format(r,int(reg_lambda*10)) # path to which we will save the model\n",
    "        model_P[k+r*N_LAMBDA] = MLP(N_INPUTS,N_HIDDEN_NEURONS,N_OUTPUTS,device).to(device) # create the model\n",
    "        l2_reg = torch.tensor(1,device=device) # create the l2 regularization value tensor\n",
    "        optimizer = torch.optim.SGD(model_P[k+r*N_LAMBDA].parameters(), lr=1e-2, momentum=0.9) # set the function for SGD\n",
    "        criterion = nn.CrossEntropyLoss() # set the loss function\n",
    "        \n",
    "        # note that cross-entropy loss expects the indices of the class, not the one-hot. So, for A = [1,0,0,...] and B = [0,1,0,...], A is 0 and B is 1\n",
    "        \n",
    "        for epoch in range(N_EPOCHS): # for each training epoch\n",
    "            nps = 0\n",
    "            running_train_loss=0\n",
    "            running_train_acc=0\n",
    "            model_P[k+r*N_LAMBDA].train() \n",
    "            for p, param in enumerate(model_P[k+r*N_LAMBDA].parameters()): # go through all the model parameters\n",
    "                if param.requires_grad:\n",
    "                    plist = torch.flatten(param.data) # set the list of parameters\n",
    "                    for j in range(plist.size(0)):\n",
    "                        while nps < Phist_P.shape[0]:\n",
    "                            Phist_P[nps,epoch,k,r]=plist[j].item() # update the parameters\n",
    "                            nps+=1\n",
    "\n",
    "            for i, (x, y_tar) in enumerate(trainloader):\n",
    "                l2_reg = 0\n",
    "                x, y_tar = x.to(device), y_tar.to(device) # x is the training set, y_tar is the output label\n",
    "                x = x-0.3\n",
    "                optimizer.zero_grad() # set gradients to 0\n",
    "                y_pred = model_P[k+r*N_LAMBDA](x.view(x.shape[0],x.shape[1]*x.shape[2])) # compute the prediction. \n",
    "                loss = criterion(y_pred,y_tar) \n",
    "                for p,param in enumerate(model_P[k+r*N_LAMBDA].parameters()):\n",
    "                    if param.requires_grad and len(param.shape)==2:\n",
    "                        if param.shape[0]==N_HIDDEN_NEURONS and param.shape[1]==N_HIDDEN_NEURONS:\n",
    "                            l2_reg = l2_reg + param[:gidx,:gidx].norm(p=1) # update the l2 regularization constant\n",
    "                            l2_reg = l2_reg + param[gidx:,gidx:].norm(p=1)\n",
    "                        elif param.shape[1]==N_HIDDEN_NEURONS:\n",
    "                            l2_reg = l2_reg + param[:,gidx:].norm(p=1)\n",
    "                        elif param.shape[0]==N_HIDDEN_NEURONS:\n",
    "                            l2_reg = l2_reg + param[:gidx,:].norm(p=1)\n",
    "                regval_P.append(l2_reg.item()) # add the l2 regularization to  the running list\n",
    "                loss = loss + l2_reg*reg_lambda/BATCH_SIZE # compute the loss\n",
    "                loss.backward() # backpropogate the loss\n",
    "                optimizer.step() # run SGD\n",
    "                running_train_loss+=loss.item()\n",
    "                running_train_acc+=get_accuracy(y_pred, y_tar) # compute accuracy\n",
    "            \n",
    "            running_test_acc=0\n",
    "            running_test_loss=0\n",
    "            model_P[k+r*N_LAMBDA].eval()\n",
    "            for i,(x_test, y_test_tar) in enumerate(testloader):\n",
    "                x_test, y_test_tar = x_test.to(device), y_test_tar.to(device)\n",
    "                x_test = x_test - 0.3\n",
    "                y_test_pred = model_P[k+r*N_LAMBDA](x_test.view(x_test.shape[0],x_test.shape[1]*x_test.shape[2]))\n",
    "                loss = criterion(y_test_pred,y_test_tar)\n",
    "                \n",
    "                running_test_loss+=loss.item()\n",
    "                running_test_acc+=get_accuracy(y_test_pred, y_test_tar)\n",
    "                \n",
    "            train_loss_P[epoch,k,r] = running_train_loss/len(trainloader)\n",
    "            train_acc_P[epoch,k,r] = running_train_acc/len(trainloader)\n",
    "            test_loss_P[epoch,k,r] = running_test_loss/len(testloader)\n",
    "            test_acc_P[epoch,k,r] = running_test_acc/len(testloader)\n",
    "            print(train_acc_P[epoch,k,r])\n",
    "            \n",
    "        # save the model and free the memory  \n",
    "        torch.save(model_P[k+r*N_LAMBDA].state_dict(), model_path)\n",
    "        model_P[k+r*N_LAMBDA] = [None]\n",
    "        del(l2_reg,loss,optimizer,criterion,plist,param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a27eb8898>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.imshow(x[0,:,:])\n",
    "#plt.plot(y_pred.detach().numpy()[0,:])\n",
    "#torch.max(y_pred,1)\n",
    "plt.plot(np.mean(test_acc_P,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-7-4c48a8559e7c>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-7-4c48a8559e7c>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    def readtxt(txt_name = 'anna.txt')\u001b[0m\n\u001b[0m                                      ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def readtxt(txt_name = 'anna.txt'):\n",
    "    dir_path = os.path.dirname(os.path.realpath(__file__))\n",
    "    txt_file = os.path.join(dir_path,txt_name)\n",
    "    # load the whole book\n",
    "    file = open(self.txt_file)\n",
    "    alltxt = file.read()\n",
    "    # remove newline formmating\n",
    "    alltxt = alltxt.replace(\"\\n\\n\", \"&\").replace(\"\\n\", \" \").replace(\"&\", \"\\n\")\n",
    "    # define categories\n",
    "    categories = list(sorted(set(alltxt)))\n",
    "    # integer encode\n",
    "    label_encoder = LabelEncoder()\n",
    "    label_encoder.fit(categories)\n",
    "    integer_encoded = torch.LongTensor(label_encoder.transform(list(alltxt)))\n",
    "    return integer_encoded, categories\n",
    "\n",
    "# def onehotencode(integer_encoded_batch,n_cat):\n",
    "    \n",
    "def get_next_batch(dat,batch_size):\n",
    "    x_int = \n",
    "    y_int = \n",
    "    x_hot = onehotencode(x_int): \n",
    "    return x_hot, y_int \n",
    "    \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
